{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax Data Science Challenge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given the data of the users and their engagement data. We must find the most important factors contributing to user adoption.\n",
    "Let us first read in the user-engagement data and filter those users who have accessed the product atleast thrice on three separate days in a seven day period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries\n",
    "\n",
    "As this is an investigative study, we will import and use libraries as and when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the user-engagement data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            time_stamp  user_id  visited\n0  2014-04-22 03:53:30        1        1\n1  2013-11-15 03:45:04        2        1\n2  2013-11-29 03:45:04        2        1\n3  2013-12-09 03:45:04        2        1\n4  2013-12-25 03:45:04        2        1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_stamp</th>\n      <th>user_id</th>\n      <th>visited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014-04-22 03:53:30</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2013-11-15 03:45:04</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2013-11-29 03:45:04</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013-12-09 03:45:04</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013-12-25 03:45:04</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "user_engagement = pd.read_csv('../relax_challenge/takehome_user_engagement.csv')\n",
    "user_engagement.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with dates\n",
    "We convert the 'timestamp' column into the appropriate datatype and also group the engagement data by date(as multiple times within the same day counts as once towards adoption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagement['time_stamp'] = user_engagement['time_stamp'].astype('datetime64')\n",
    "user_engagement['date'] = user_engagement['time_stamp'].dt.date\n",
    "user_engagement = user_engagement.groupby(['date','user_id']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demarcate Adopted users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = user_engagement.sort_values(['user_id', 'date']) - user_engagement.sort_values(['user_id', 'date']).shift(-2)\n",
    "adopted_users = user_engagement.sort_values(['user_id', 'date'])[(condition['date'].dt.days >= -7) & (condition['user_id'] == 0)]['user_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the users data and convert dates to appropriate datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv('../relax_challenge/takehome_users.csv', encoding = 'latin-1')\n",
    "user_data['creation_time'] = user_data['creation_time'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the features given in the dataset, we add an additional feature which indicates if the user was invited by an adopted user.\n",
    "We then drop other details such as personal information so that they will not interfere in our predictive modelling. We also onehot encode the 'creation_source' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['invited_by_adopted_user'] = user_data['invited_by_user_id'].map(lambda x: int(x in adopted_users))\n",
    "user_data = pd.concat([user_data, pd.get_dummies(user_data['creation_source'])], axis = 1)\n",
    "user_data['adopted_user'] = user_data['object_id'].map(lambda x: int(x in adopted_users))\n",
    "user_data.drop(['name', 'email', 'creation_source', 'last_session_creation_time', 'object_id', 'invited_by_user_id', 'org_id', 'creation_time'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       0.86      1.00      0.92      2578\n           1       0.00      0.00      0.00       422\n\n    accuracy                           0.86      3000\n   macro avg       0.43      0.50      0.46      3000\nweighted avg       0.74      0.86      0.79      3000\n\n              precision    recall  f1-score   support\n\n           0       0.86      1.00      0.92      2578\n           1       0.00      0.00      0.00       422\n\n    accuracy                           0.86      3000\n   macro avg       0.43      0.50      0.46      3000\nweighted avg       0.74      0.86      0.79      3000\n\n              precision    recall  f1-score   support\n\n           0       0.86      1.00      0.92      2578\n           1       0.00      0.00      0.00       422\n\n    accuracy                           0.86      3000\n   macro avg       0.43      0.50      0.46      3000\nweighted avg       0.74      0.86      0.79      3000\n\n              precision    recall  f1-score   support\n\n           0       0.86      1.00      0.92      2578\n           1       0.00      0.00      0.00       422\n\n    accuracy                           0.86      3000\n   macro avg       0.43      0.50      0.46      3000\nweighted avg       0.74      0.86      0.79      3000\n\n              precision    recall  f1-score   support\n\n           0       0.86      1.00      0.92      2578\n           1       0.00      0.00      0.00       422\n\n    accuracy                           0.86      3000\n   macro avg       0.43      0.50      0.46      3000\nweighted avg       0.74      0.86      0.79      3000\n\n              precision    recall  f1-score   support\n\n           0       0.86      1.00      0.92      2578\n           1       0.00      0.00      0.00       422\n\n    accuracy                           0.86      3000\n   macro avg       0.43      0.50      0.46      3000\nweighted avg       0.74      0.86      0.79      3000\n\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "X = user_data.values[:,:-1]\n",
    "y = user_data.values[:,-1]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, shuffle = True)\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "for C in Cs:\n",
    "    clf = LogisticRegression(C = C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    Y_pred_valid = clf.predict(X_valid)\n",
    "    print(classification_report(y_valid, Y_pred_valid))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred_valid = clf.predict(X_valid)\n",
    "print(classification_report(y_valid, Y_pred_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10344"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import imblearn.over_sampling as imb\n",
    "oversample = imb.SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       0.56      0.61      0.58      2576\n           1       0.57      0.52      0.54      2596\n\n    accuracy                           0.56      5172\n   macro avg       0.56      0.56      0.56      5172\nweighted avg       0.57      0.56      0.56      5172\n\n              precision    recall  f1-score   support\n\n           0       0.58      0.49      0.53      2576\n           1       0.56      0.64      0.60      2596\n\n    accuracy                           0.57      5172\n   macro avg       0.57      0.57      0.56      5172\nweighted avg       0.57      0.57      0.56      5172\n\n              precision    recall  f1-score   support\n\n           0       0.58      0.49      0.53      2576\n           1       0.56      0.64      0.60      2596\n\n    accuracy                           0.57      5172\n   macro avg       0.57      0.57      0.56      5172\nweighted avg       0.57      0.57      0.56      5172\n\n              precision    recall  f1-score   support\n\n           0       0.58      0.49      0.53      2576\n           1       0.56      0.64      0.60      2596\n\n    accuracy                           0.57      5172\n   macro avg       0.57      0.57      0.56      5172\nweighted avg       0.57      0.57      0.56      5172\n\n              precision    recall  f1-score   support\n\n           0       0.58      0.49      0.53      2576\n           1       0.56      0.64      0.60      2596\n\n    accuracy                           0.57      5172\n   macro avg       0.57      0.57      0.56      5172\nweighted avg       0.57      0.57      0.56      5172\n\n              precision    recall  f1-score   support\n\n           0       0.58      0.49      0.53      2576\n           1       0.56      0.64      0.60      2596\n\n    accuracy                           0.57      5172\n   macro avg       0.57      0.57      0.56      5172\nweighted avg       0.57      0.57      0.56      5172\n\n"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, shuffle = True)\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "for C in Cs:\n",
    "    clf = LogisticRegression(C = C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    Y_pred_valid = clf.predict(X_valid)\n",
    "    print(classification_report(y_valid, Y_pred_valid))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred_valid = clf.predict(X_valid)\n",
    "print(classification_report(y_valid, Y_pred_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       0.87      0.84      0.85      1038\n           1       0.14      0.18      0.16       162\n\n    accuracy                           0.75      1200\n   macro avg       0.51      0.51      0.51      1200\nweighted avg       0.77      0.75      0.76      1200\n\n"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "X = user_data.values[:,:-1]\n",
    "y = user_data.values[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size = 0.1)\n",
    "clf = DecisionTreeClassifier()\n",
    "param_grid = {\"criterion\": [\"gini\", \"entropy\"], \n",
    "                       \"max_depth\": [1,2,.3,4,5,6,None], \n",
    "                       \"max_features\": [\"sqrt\", \"log2\", None], \n",
    "                       \"random_state\" : [5], \n",
    "                       \"class_weight\" : [\"balanced\", {0: 1, 1:10}, {0:1, 1:15}], \"presort\": [True]}\n",
    "gs = GridSearchCV(estimator = clf, \n",
    "                   param_grid = param_grid, \n",
    "                   n_jobs = 2, \n",
    "                   cv = None)\n",
    "gs.fit(X_train, y_train)\n",
    "best_clf = gs.best_estimator_\n",
    "Y_test = best_clf.predict(X_test)\n",
    "print(classification_report(y_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz.backend as be\n",
    "from dtreeviz.trees import *\n",
    "viz = dtreeviz(best_clf, \n",
    "               X, \n",
    "               y,\n",
    "               target_name = 'Adopted User',\n",
    "               feature_names = user_data.columns[:-1],\n",
    "               class_names=[\"Adopted User\", \"Not adopted user\"],\n",
    "              fancy=False )\n",
    "\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitd2f58a4918ec49a6be3098fab8dcc577",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}